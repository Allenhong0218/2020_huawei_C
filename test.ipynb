{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600401308437",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[93m--- Optimizing SVM ---\u001b[0m\n|   iter    |  target   |  degree   |   expC    | expGamma  |\n-------------------------------------------------------------\n| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8392  \u001b[0m | \u001b[0m 2.503   \u001b[0m | \u001b[0m-2.454   \u001b[0m | \u001b[0m-2.542   \u001b[0m |\n| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8522  \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 0.2855  \u001b[0m | \u001b[95m-3.292   \u001b[0m |\n| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8893  \u001b[0m | \u001b[95m 2.226   \u001b[0m | \u001b[95m-2.402   \u001b[0m | \u001b[95m-1.863   \u001b[0m |\n| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8483  \u001b[0m | \u001b[0m 1.745   \u001b[0m | \u001b[0m-0.3762  \u001b[0m | \u001b[0m-3.21    \u001b[0m |\n| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8392  \u001b[0m | \u001b[0m 2.243   \u001b[0m | \u001b[0m-0.7545  \u001b[0m | \u001b[0m-3.343   \u001b[0m |\n| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8214  \u001b[0m | \u001b[0m 1.647   \u001b[0m | \u001b[0m-2.013   \u001b[0m | \u001b[0m-2.667   \u001b[0m |\n| \u001b[95m 7       \u001b[0m | \u001b[95m 0.8904  \u001b[0m | \u001b[95m 2.212   \u001b[0m | \u001b[95m-2.41    \u001b[0m | \u001b[95m-1.845   \u001b[0m |\n| \u001b[95m 8       \u001b[0m | \u001b[95m 0.9392  \u001b[0m | \u001b[95m 2.492   \u001b[0m | \u001b[95m-2.367   \u001b[0m | \u001b[95m-1.218   \u001b[0m |\n| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-1.442   \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9168  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-3.0     \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8542  \u001b[0m | \u001b[0m 1.835   \u001b[0m | \u001b[0m-1.818   \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9193  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-2.298   \u001b[0m | \u001b[0m-1.292   \u001b[0m |\n| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9387  \u001b[0m | \u001b[0m 2.194   \u001b[0m | \u001b[0m-3.0     \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8435  \u001b[0m | \u001b[0m 1.21    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.5205  \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9062  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-2.509   \u001b[0m |\n| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8263  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-4.0     \u001b[0m |\n| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.147   \u001b[0m | \u001b[0m-1.916   \u001b[0m |\n| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 2.51    \u001b[0m | \u001b[0m-3.0     \u001b[0m | \u001b[0m-1.405   \u001b[0m |\n| \u001b[0m 21      \u001b[0m | \u001b[0m 0.844   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-3.253   \u001b[0m |\n| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8371  \u001b[0m | \u001b[0m 1.148   \u001b[0m | \u001b[0m-3.0     \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[95m 23      \u001b[0m | \u001b[95m 0.941   \u001b[0m | \u001b[95m 2.515   \u001b[0m | \u001b[95m-2.636   \u001b[0m | \u001b[95m-1.0     \u001b[0m |\n| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-0.3031  \u001b[0m | \u001b[0m-1.765   \u001b[0m |\n| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8432  \u001b[0m | \u001b[0m 1.867   \u001b[0m | \u001b[0m 0.2008  \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8214  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m-3.0     \u001b[0m | \u001b[0m-4.0     \u001b[0m |\n| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9212  \u001b[0m | \u001b[0m 2.496   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m-1.853   \u001b[0m |\n| \u001b[0m 28      \u001b[0m | \u001b[0m 0.9212  \u001b[0m | \u001b[0m 2.967   \u001b[0m | \u001b[0m 1.987   \u001b[0m | \u001b[0m-1.925   \u001b[0m |\n| \u001b[0m 29      \u001b[0m | \u001b[0m 0.9372  \u001b[0m | \u001b[0m 2.666   \u001b[0m | \u001b[0m-2.198   \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[95m 30      \u001b[0m | \u001b[95m 0.9411  \u001b[0m | \u001b[95m 2.217   \u001b[0m | \u001b[95m-2.59    \u001b[0m | \u001b[95m-1.0     \u001b[0m |\n| \u001b[0m 31      \u001b[0m | \u001b[0m 0.9394  \u001b[0m | \u001b[0m 2.317   \u001b[0m | \u001b[0m-2.785   \u001b[0m | \u001b[0m-1.0     \u001b[0m |\n| \u001b[0m 32      \u001b[0m | \u001b[0m 0.8248  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-3.0     \u001b[0m | \u001b[0m-4.0     \u001b[0m |\n| \u001b[0m 33      \u001b[0m | \u001b[0m 0.918   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-1.261   \u001b[0m | \u001b[0m-1.946   \u001b[0m |\n| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8448  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2412  \u001b[0m | \u001b[0m-4.0     \u001b[0m |\n| \u001b[0m 35      \u001b[0m | \u001b[0m 0.9381  \u001b[0m | \u001b[0m 2.494   \u001b[0m | \u001b[0m-2.304   \u001b[0m | \u001b[0m-1.018   \u001b[0m |\n| \u001b[0m 36      \u001b[0m | \u001b[0m 0.881   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-0.5481  \u001b[0m | \u001b[0m-2.5     \u001b[0m |\n| \u001b[0m 37      \u001b[0m | \u001b[0m 0.9244  \u001b[0m | \u001b[0m 2.172   \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m-2.286   \u001b[0m |\n| \u001b[0m 38      \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 1.888   \u001b[0m | \u001b[0m 1.994   \u001b[0m | \u001b[0m-2.275   \u001b[0m |\n| \u001b[0m 39      \u001b[0m | \u001b[0m 0.9274  \u001b[0m | \u001b[0m 2.186   \u001b[0m | \u001b[0m 0.8679  \u001b[0m | \u001b[0m-2.075   \u001b[0m |\n| \u001b[0m 40      \u001b[0m | \u001b[0m 0.9212  \u001b[0m | \u001b[0m 2.355   \u001b[0m | \u001b[0m 1.359   \u001b[0m | \u001b[0m-1.583   \u001b[0m |\n| \u001b[0m 41      \u001b[0m | \u001b[0m 0.9363  \u001b[0m | \u001b[0m 2.554   \u001b[0m | \u001b[0m 1.121   \u001b[0m | \u001b[0m-2.562   \u001b[0m |\n| \u001b[0m 42      \u001b[0m | \u001b[0m 0.923   \u001b[0m | \u001b[0m 2.602   \u001b[0m | \u001b[0m 1.487   \u001b[0m | \u001b[0m-2.195   \u001b[0m |\n| \u001b[0m 43      \u001b[0m | \u001b[0m 0.9373  \u001b[0m | \u001b[0m 2.054   \u001b[0m | \u001b[0m 1.01    \u001b[0m | \u001b[0m-2.6     \u001b[0m |\n| \u001b[0m 44      \u001b[0m | \u001b[0m 0.8487  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5819  \u001b[0m | \u001b[0m-2.281   \u001b[0m |\n| \u001b[0m 45      \u001b[0m | \u001b[0m 0.938   \u001b[0m | \u001b[0m 2.446   \u001b[0m | \u001b[0m 0.6737  \u001b[0m | \u001b[0m-2.503   \u001b[0m |\n| \u001b[0m 46      \u001b[0m | \u001b[0m 0.888   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.6856  \u001b[0m | \u001b[0m-2.863   \u001b[0m |\n| \u001b[0m 47      \u001b[0m | \u001b[0m 0.9356  \u001b[0m | \u001b[0m 2.4     \u001b[0m | \u001b[0m 0.9811  \u001b[0m | \u001b[0m-2.386   \u001b[0m |\n| \u001b[95m 48      \u001b[0m | \u001b[95m 0.9411  \u001b[0m | \u001b[95m 2.308   \u001b[0m | \u001b[95m 1.286   \u001b[0m | \u001b[95m-2.94    \u001b[0m |\n| \u001b[0m 49      \u001b[0m | \u001b[0m 0.9372  \u001b[0m | \u001b[0m 2.324   \u001b[0m | \u001b[0m 0.1635  \u001b[0m | \u001b[0m-2.149   \u001b[0m |\n| \u001b[0m 50      \u001b[0m | \u001b[0m 0.9328  \u001b[0m | \u001b[0m 2.651   \u001b[0m | \u001b[0m 0.3895  \u001b[0m | \u001b[0m-1.957   \u001b[0m |\n| \u001b[0m 51      \u001b[0m | \u001b[0m 0.9405  \u001b[0m | \u001b[0m 2.322   \u001b[0m | \u001b[0m-0.7242  \u001b[0m | \u001b[0m-1.922   \u001b[0m |\n| \u001b[0m 52      \u001b[0m | \u001b[0m 0.8553  \u001b[0m | \u001b[0m 1.836   \u001b[0m | \u001b[0m-0.5478  \u001b[0m | \u001b[0m-2.068   \u001b[0m |\n| \u001b[0m 53      \u001b[0m | \u001b[0m 0.9374  \u001b[0m | \u001b[0m 2.555   \u001b[0m | \u001b[0m-0.9406  \u001b[0m | \u001b[0m-1.573   \u001b[0m |\n| \u001b[0m 54      \u001b[0m | \u001b[0m 0.9369  \u001b[0m | \u001b[0m 2.467   \u001b[0m | \u001b[0m-1.166   \u001b[0m | \u001b[0m-1.959   \u001b[0m |\n| \u001b[0m 55      \u001b[0m | \u001b[0m 0.9411  \u001b[0m | \u001b[0m 2.632   \u001b[0m | \u001b[0m-0.7781  \u001b[0m | \u001b[0m-1.935   \u001b[0m |\n=============================================================\nFinal result: {'target': 0.941103071172555, 'params': {'degree': 2.308191678839459, 'expC': 1.2860781928785858, 'expGamma': -2.9404127919761014}}\n"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.util import Colours\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    \"\"\"Synthetic binary classification dataset.\"\"\"\n",
    "    data, targets = make_classification(\n",
    "        n_samples=1000,\n",
    "        n_features=45,\n",
    "        n_informative=12,\n",
    "        n_redundant=7,\n",
    "        random_state=134985745,\n",
    "    )\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def svc_cv(C, gamma, degree, data, targets):\n",
    "    \"\"\"SVC cross validation.\n",
    "    This function will instantiate a SVC classifier with parameters C and\n",
    "    gamma. Combined with data and targets this will in turn be used to perform\n",
    "    cross validation. The result of cross validation is returned.\n",
    "    Our goal is to find combinations of C and gamma that maximizes the roc_auc\n",
    "    metric.\n",
    "    \"\"\"\n",
    "    estimator = SVC(C=C, gamma=gamma, kernel='poly', degree=degree, random_state=2)\n",
    "    cval = cross_val_score(estimator, data, targets, scoring='roc_auc', cv=4)\n",
    "    return cval.mean()\n",
    "\n",
    "\n",
    "def rfc_cv(n_estimators, min_samples_split, max_features, data, targets):\n",
    "    \"\"\"Random Forest cross validation.\n",
    "    This function will instantiate a random forest classifier with parameters\n",
    "    n_estimators, min_samples_split, and max_features. Combined with data and\n",
    "    targets this will in turn be used to perform cross validation. The result\n",
    "    of cross validation is returned.\n",
    "    Our goal is to find combinations of n_estimators, min_samples_split, and\n",
    "    max_features that minimzes the log loss.\n",
    "    \"\"\"\n",
    "    estimator = RFC(\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_split=min_samples_split,\n",
    "        max_features=max_features,\n",
    "        random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, data, targets, scoring='neg_log_loss', cv=4)\n",
    "    return cval.mean()\n",
    "\n",
    "\n",
    "def optimize_svc(data, targets):\n",
    "    \"\"\"Apply Bayesian Optimization to SVC parameters.\"\"\"\n",
    "\n",
    "    def svc_crossval(expC, expGamma, degree):\n",
    "        \"\"\"Wrapper of SVC cross validation.\n",
    "        Notice how we transform between regular and log scale. While this\n",
    "        is not technically necessary, it greatly improves the performance\n",
    "        of the optimizer.\n",
    "        \"\"\"\n",
    "        C = 10 ** expC\n",
    "        gamma = 10 ** expGamma\n",
    "        degree = int(degree)\n",
    "        return svc_cv(C=C, gamma=gamma, degree=degree, data=data, targets=targets)\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=svc_crossval,\n",
    "        pbounds={\"expC\": (-3, 2), \"expGamma\": (-4, -1), \"degree\": (1, 3)},\n",
    "        random_state=3333,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=50)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data, targets = get_data()\n",
    "    # print(data, targets)\n",
    "    print(Colours.yellow(\"--- Optimizing SVM ---\"))\n",
    "    opt = optimize_svc(data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}